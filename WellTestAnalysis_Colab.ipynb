{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb41afd",
   "metadata": {},
   "source": [
    "# Interactive Well Test Analysis and IPR Optimization\n",
    "\n",
    "This Colab notebook adapts the `WellTestOptimizer` application for an interactive classroom environment.\n",
    "It includes setup instructions, the core optimizer class (GUI removed), data loading guidance, example runs, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217ac99",
   "metadata": {},
   "source": [
    "## 1) Setup: Install dependencies\n",
    "\n",
    "Run the cell below to install required packages in Colab. If running locally, install the same packages into your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install runtime dependencies (Colab) - uncomment if needed\n",
    "# !pip install pandas numpy matplotlib scipy openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee4313",
   "metadata": {},
   "source": [
    "## 2) Imports\n",
    "\n",
    "Import the libraries we will use. Colab already has many preinstalled packages; install extras above if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbec34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import io, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ac1f8",
   "metadata": {},
   "source": [
    "## 3) Core optimizer class (adapted from `well_test_optimizer.py`)\n",
    "\n",
    "The GUI components are removed. The class provides: calculate_ipr, objective, optimize_group, process_data, and generate_ipr_curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560def06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellTestOptimizer:\n",
    "    \"\"\"Well Test Data Optimizer for PI and SBHP (Notebook-friendly)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.results = []\n",
    "\n",
    "    def calculate_ipr(self, fbhp, sbhp, pbub, pi):\n",
    "        # enforce non-negative inputs\n",
    "        fbhp = max(0.0, float(fbhp))\n",
    "        sbhp = max(0.0, float(sbhp))\n",
    "        pbub = max(0.0, float(pbub))\n",
    "        pi = max(0.0, float(pi))\n",
    "\n",
    "        # Physical: if FBHP > SBHP, no production\n",
    "        if fbhp > sbhp:\n",
    "            return 0.0\n",
    "\n",
    "        # Case 1: Linear PI (single-phase) - FBHP >= Pbub and SBHP > Pbub\n",
    "        if (fbhp >= pbub) and (sbhp > pbub):\n",
    "            ql = pi * (sbhp - fbhp)\n",
    "        # Case 2: Modified Vogel (unsaturated reservoir) - FBHP < Pbub and SBHP > Pbub\n",
    "        elif (fbhp < pbub) and (sbhp > pbub):\n",
    "            ql_at_pbub = pi * (sbhp - pbub)\n",
    "            if pbub > 0.0:\n",
    "                fbhp_pbub_ratio = fbhp / pbub\n",
    "                vogel_component = (pi * pbub / 1.8) * (1 - 0.2 * fbhp_pbub_ratio - 0.8 * fbhp_pbub_ratio**2)\n",
    "                ql = ql_at_pbub + vogel_component\n",
    "            else:\n",
    "                ql = ql_at_pbub\n",
    "        # Case 3: Standard Vogel (saturated reservoir) - SBHP <= Pbub\n",
    "        else:\n",
    "            if sbhp > 0.0:\n",
    "                fbhp_sbhp_ratio = fbhp / sbhp\n",
    "                ql = (pi * sbhp / 1.8) * (1 - 0.2 * fbhp_sbhp_ratio - 0.8 * fbhp_sbhp_ratio**2)\n",
    "            else:\n",
    "                ql = 0.0\n",
    "\n",
    "        return max(0.0, ql)\n",
    "\n",
    "    def calculate_ql_max(self, sbhp, pbub, pi):\n",
    "        return self.calculate_ipr(0.0, sbhp, pbub, pi)\n",
    "\n",
    "    def objective_function(self, params, fbhp_data, q_actual, pbub):\n",
    "        sbhp, pi = params\n",
    "        # penalty for non-physical parameters\n",
    "        if sbhp <= 0 or pi <= 0:\n",
    "            return 1e12\n",
    "        max_fbhp = np.max(fbhp_data)\n",
    "        if sbhp <= max_fbhp:\n",
    "            return 1e12\n",
    "\n",
    "        q_calculated = np.array([self.calculate_ipr(f, sbhp, pbub, pi) for f in fbhp_data])\n",
    "        if np.any(q_calculated < 0):\n",
    "            return 1e12\n",
    "\n",
    "        sse = np.sum((q_actual - q_calculated)**2)\n",
    "        # soft penalty for extreme values\n",
    "        if sbhp > 15000 or pi > 1000:\n",
    "            sse += 1e8\n",
    "        return sse\n",
    "\n",
    "    def optimize_group(self, group_data, pbub, sbhp_guess, pi_guess):\n",
    "        fbhp_data = group_data['Pwf'].values\n",
    "        q_actual = group_data['Total Rate'].values\n",
    "\n",
    "        # data checks\n",
    "        if np.any(fbhp_data <= 0) or np.any(q_actual <= 0):\n",
    "            return {'success': False, 'message': 'Non-positive data values detected'}\n",
    "\n",
    "        fbhp_rate_correlation = np.corrcoef(fbhp_data, q_actual)[0,1] if len(fbhp_data) > 1 else 0.0\n",
    "        if np.isnan(fbhp_rate_correlation):\n",
    "            fbhp_rate_correlation = 0.0\n",
    "        if fbhp_rate_correlation > 0.3:\n",
    "            return {'success': False, 'message': f'Data quality issue: positive FBHP-rate correlation ({fbhp_rate_correlation:.3f}).'}\n",
    "\n",
    "        max_fbhp = np.max(fbhp_data)\n",
    "        sbhp_lower = max_fbhp + 100\n",
    "        sbhp_upper = min(8000.0, max_fbhp + 3000.0)\n",
    "\n",
    "        rate_range = np.max(q_actual) - np.min(q_actual)\n",
    "        fbhp_range = np.max(fbhp_data) - np.min(fbhp_data)\n",
    "        estimated_pi = (rate_range / fbhp_range) if fbhp_range > 10 else 1.0\n",
    "        pi_lower = max(0.01, estimated_pi * 0.1)\n",
    "        pi_upper = min(50.0, estimated_pi * 10)\n",
    "\n",
    "        sbhp_guess = float(np.clip(sbhp_guess, sbhp_lower + 100, sbhp_upper - 100)) if sbhp_upper - sbhp_lower > 200 else (sbhp_lower + 200.0)\n",
    "        pi_guess = float(np.clip(pi_guess, pi_lower, pi_upper))\n",
    "\n",
    "        initial_guess = [sbhp_guess, pi_guess]\n",
    "        bounds = [(sbhp_lower, sbhp_upper), (pi_lower, pi_upper)]\n",
    "\n",
    "        try:\n",
    "            result = minimize(self.objective_function, initial_guess, args=(fbhp_data, q_actual, pbub), method='L-BFGS-B', bounds=bounds)\n",
    "            if result.success:\n",
    "                sbhp_opt, pi_opt = result.x\n",
    "                q_calculated = np.array([self.calculate_ipr(f, sbhp_opt, pbub, pi_opt) for f in fbhp_data])\n",
    "                ss_res = np.sum((q_actual - q_calculated)**2)\n",
    "                ss_tot = np.sum((q_actual - np.mean(q_actual))**2)\n",
    "                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "                rmse = np.sqrt(ss_res / len(q_actual))\n",
    "                if r_squared >= 0.8: fit_quality = 'excellent'\n",
    "                elif r_squared >= 0.5: fit_quality = 'good'\n",
    "                elif r_squared >= 0.0: fit_quality = 'poor'\n",
    "                else: fit_quality = 'very_poor'\n",
    "                return {\n",
    "                    'sbhp': float(sbhp_opt), 'pi': float(pi_opt), 'r_squared': float(r_squared), 'rmse': float(rmse),\n",
    "                    'fit_quality': fit_quality, 'sse': float(result.fun), 'success': True,\n",
    "                    'q_actual': q_actual.tolist(), 'q_calculated': q_calculated.tolist(), 'fbhp': fbhp_data.tolist(),\n",
    "                    'dates': group_data['Test Date'].values,\n",
    "                }\n",
    "            else:\n",
    "                return {'success': False, 'message': result.message}\n",
    "        except Exception as e:\n",
    "            return {'success': False, 'message': str(e)}\n",
    "\n",
    "    def process_data(self, data, pbub, sbhp_guess, pi_guess, group_size=5):\n",
    "        data_sorted = data.sort_values('Test Date').reset_index(drop=True)\n",
    "        self.data = data_sorted\n",
    "        self.results = []\n",
    "        num_groups = len(data_sorted) // group_size\n",
    "        for i in range(num_groups):\n",
    "            start_idx = i * group_size\n",
    "            end_idx = start_idx + group_size\n",
    "            group_data = data_sorted.iloc[start_idx:end_idx]\n",
    "            res = self.optimize_group(group_data, pbub, sbhp_guess, pi_guess)\n",
    "            if res.get('success'):\n",
    "                res['group_id'] = i+1\n",
    "                res['start_date'] = group_data['Test Date'].min()\n",
    "                res['end_date'] = group_data['Test Date'].max()\n",
    "                self.results.append(res)\n",
    "        return self.results\n",
    "\n",
    "    def generate_ipr_curve(self, sbhp, pbub, pi):\n",
    "        fbhp_range = np.linspace(0.0, float(sbhp), 100)\n",
    "        q_range = np.array([self.calculate_ipr(f, sbhp, pbub, pi) for f in fbhp_range])\n",
    "        return fbhp_range, q_range\n",
    "\n",
    "# End of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e640661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise starter: run a sensitivity sweep over group_size and pbub for first N groups\n",
    "if 'df' in globals():\n",
    "    sweep_results = []\n",
    "    for group_size_test in [3,5,10]:\n",
    "        optimizer = WellTestOptimizer()\n",
    "        res = optimizer.process_data(df, pbub=4000.0, sbhp_guess=3500.0, pi_guess=1.0, group_size=group_size_test)\n",
    "        sweep_results.append({'group_size': group_size_test, 'num_results': len(res)})\n",
    "    import pprint; pprint.pprint(sweep_results)\n",
    "else:\n",
    "    print('Upload the CSV (Test-1 welltestdata.csv) and run the data load cell first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66084995",
   "metadata": {},
   "source": [
    "## Classroom Exercises\n",
    "\n",
    "These short exercises are designed for a 50–90 minute classroom session. Instructors: assign 1–3 per student/group.\n",
    "\n",
    "1) Sensitivity Analysis: Vary `group_size` (try 3,5,10) and observe how `SBHP` and `PI` trends change. Describe why results are more/less stable.\n",
    "\n",
    "2) Bubble Point Effect: Change `pbub` (e.g., 3000, 4000, 5000 psi) and explain how the IPR curve shapes and fit metrics change for a selected group.\n",
    "\n",
    "3) Data Quality Investigation: Intentionally remove or perturb one data point (e.g., change a `Pwf` to be higher than others) and run the optimizer. Report warnings and R² behavior.\n",
    "\n",
    "4) Cross-Comparison: Run the optimizer on two different wells/datasets and compare parameter trends and fit qualities.\n",
    "\n",
    "Each exercise should include: hypothesis, steps, results (figures/table), and interpretation in one paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed674b2d",
   "metadata": {},
   "source": [
    "## Data Format Requirements\n",
    "\n",
    "Required CSV columns:\n",
    "- `Test Date` (any pandas-parseable date)\n",
    "- `Pwf` (Flowing Bottom Hole Pressure, psi)\n",
    "- `Total Rate` (Liquid production rate, bbl/day)\n",
    "\n",
    "Data rules: no missing values in required columns, all values > 0, chronological order preferred (the notebook sorts by date)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602cd027",
   "metadata": {},
   "source": [
    "## Quick Start Guide for Students\n",
    "\n",
    "1. Upload `Test-1 welltestdata.csv` using the Colab Files pane.\n",
    "2. Run the *Imports* cell (Cell 5) and the *Core optimizer* cell (Cell 7).\n",
    "3. Run the data load cell (Cell 9) to verify the CSV loads.\n",
    "4. Run the optimization cell (Cell 11) and then the visualizations (Cell 13).\n",
    "\n",
    "Tips: Try changing `group_size`, `pbub`, and initial guesses to see how results change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427289",
   "metadata": {},
   "source": [
    "## Installation & Requirements\n",
    "\n",
    "Recommended packages (Colab already has most): pandas, numpy, matplotlib, scipy, openpyxl.\n",
    "If running locally: `pip install pandas numpy matplotlib scipy openpyxl`.\n",
    "\n",
    "System: Python 3.7+, 4GB RAM minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae363c17",
   "metadata": {},
   "source": [
    "## 4) Load example data\n",
    "\n",
    "Upload `Test-1 welltestdata.csv` to Colab (Files pane → Upload). If running locally, ensure the file is in the working directory. The cell below attempts to load that filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab helper: mount Google Drive and copy the example CSV into the session\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import shutil\n",
    "    drive.mount('/content/drive')\n",
    "    drive_src = '/content/drive/My Drive/ColabNotebooks/Test-1 welltestdata.csv'\n",
    "    if os.path.exists(drive_src):\n",
    "        shutil.copy(drive_src, './')\n",
    "        print('Copied Test-1 welltestdata.csv from Drive to session directory.')\n",
    "    else:\n",
    "        print('File not found at', drive_src, '\\nPlace the CSV in Drive under \"My Drive/ColabNotebooks/\" or upload via Files pane.')\n",
    "except Exception as e:\n",
    "    print('Drive mount not available in this environment or error occurred:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to load the provided example file\n",
    "csv_path = 'Test-1 welltestdata.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path, parse_dates=['Test Date'])\n",
    "    df = df.sort_values('Test Date').reset_index(drop=True)\n",
    "    print(f'Loaded {len(df)} records from {csv_path}')\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f'File not found: {csv_path} -- upload it to the Colab session or drive and update the path.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2bffca",
   "metadata": {},
   "source": [
    "## 5) Run optimization (example)\n",
    "\n",
    "Set parameters and run the optimizer. The example uses the uploaded `Test-1 welltestdata.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (tweak as needed)\n",
    "pbub = 4000.0\n",
    "sbhp_guess = 3500.0\n",
    "pi_guess = 1.0\n",
    "group_size = 5\n",
    "# Run optimizer if df exists\n",
    "if 'df' in globals():\n",
    "    optimizer = WellTestOptimizer()\n",
    "    results = optimizer.process_data(df, pbub, sbhp_guess, pi_guess, group_size)\n",
    "    print(f'Optimization complete. Found results for {len(results)} groups.')\n",
    "    # Convert results to DataFrame for display\n",
    "    if len(results) > 0:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df['start_date'] = pd.to_datetime(results_df['start_date']).dt.strftime('%Y-%m-%d')\n",
    "        results_df['end_date'] = pd.to_datetime(results_df['end_date']).dt.strftime('%Y-%m-%d')\n",
    "        display(results_df[['group_id','start_date','end_date','sbhp','pi','r_squared','rmse','fit_quality']])\n",
    "else:\n",
    "    print('No data loaded; please upload the CSV and run this cell again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87f46f",
   "metadata": {},
   "source": [
    "## 6) Visualizations\n",
    "\n",
    "Create the three plots: parameter trends, actual vs calculated, and IPR curves over data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results' in globals() and len(results) > 0:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Plot SBHP and PI vs group\n",
    "    fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "    ax1.plot(results_df['group_id'], results_df['sbhp'], marker='o', color='tab:blue', label='SBHP')\n",
    "    ax1.set_xlabel('Group')\n",
    "    ax1.set_ylabel('SBHP (psi)', color='tab:blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(results_df['group_id'], results_df['pi'], marker='s', color='tab:red', label='PI')\n",
    "    ax2.set_ylabel('PI (bbl/day/psi)', color='tab:red')\n",
    "    fig.tight_layout()\n",
    "    plt.title('Optimized Parameters by Group')\n",
    "    plt.show()\n",
    "\n",
    "    # Actual vs Calculated for first group\n",
    "    selected = results[0]\n",
    "    q_act = np.array(selected['q_actual'])\n",
    "    q_calc = np.array(selected['q_calculated'])\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(q_act, q_calc, alpha=0.7, edgecolor='k')\n",
    "    mn = min(q_act.min(), q_calc.min())\n",
    "    mx = max(q_act.max(), q_calc.max())\n",
    "    plt.plot([mn,mx],[mn,mx],'r--')\n",
    "    plt.xlabel('Actual Rate')\n",
    "    plt.ylabel('Calculated Rate')\n",
    "    plt.title(f'Actual vs Calculated (Group {selected[\n",
    "]}) R²={selected[\n",
    "]:.3f}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # IPR curves overlay\n",
    "    plt.figure(figsize=(10,6))\n",
    "    colors = plt.cm.viridis(np.linspace(0,1,len(results)))\n",
    "    for i,res in enumerate(results):\n",
    "        fb, ql = optimizer.generate_ipr_curve(res['sbhp'], pbub, res['pi'])\n",
    "        plt.plot(ql, fb, color=colors[i], label=f\"Group {res['group_id']} IPR\")\n",
    "        plt.scatter(res['q_actual'], res['fbhp'], color=colors[i], edgecolor='k', alpha=0.7)\n",
    "    plt.xlabel('Liquid Flow Rate (bbl/day)')\n",
    "    plt.ylabel('FBHP (psi)')\n",
    "    plt.title('IPR Curves with Measured Data')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No optimization results to plot. Run the optimization cell first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abebd9",
   "metadata": {},
   "source": [
    "## 7) Exporting results (optional)\n",
    "\n",
    "You can export `results_df` to Excel using `pandas.ExcelWriter`. In Colab, save to Drive or download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: save results to Excel locally (or to Colab drive)\n",
    "if 'results_df' in globals():\n",
    "    out_name = 'well_test_results.xlsx'\n",
    "    results_df.to_excel(out_name, index=False)\n",
    "    print(f'Saved results to {out_name}')\n",
    "else:\n",
    "    print('No results to save.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc518d57",
   "metadata": {},
   "source": [
    "---\n",
    "### Notes and next steps\n",
    "- You can copy additional text from `USER_GUIDE.md` into markdown cells for classroom instructions.\n",
    "- Consider adding small exercises and pre-uploaded CSVs for students."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
