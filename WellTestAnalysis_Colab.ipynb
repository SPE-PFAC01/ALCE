{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb41afd",
   "metadata": {},
   "source": [
    "# Well Test Analysis and Productivity Index Optimization\n",
    "\n",
    "This notebook teaches you how to analyze well test data and optimize productivity index (PI) and reservoir pressure parameters using engineering methods. You'll learn to evaluate different mathematical models and understand which ones provide reliable results for field applications.\n",
    "\n",
    "**What You'll Learn:**\n",
    "- How to analyze well test data systematically\n",
    "- Methods for calculating productivity index and reservoir pressure\n",
    "- How to evaluate model accuracy using engineering criteria\n",
    "- When to trust mathematical models for field decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217ac99",
   "metadata": {},
   "source": [
    "## Step 1: Setup Required Tools\n",
    "\n",
    "Run the cell below to install the mathematical and plotting tools we need. Google Colab usually has these already installed, but this ensures everything is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install runtime dependencies (Colab) - uncomment if needed\n",
    "# !pip install pandas numpy matplotlib scipy openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee4313",
   "metadata": {},
   "source": [
    "## Step 2: Load Mathematical Tools\n",
    "\n",
    "Import the tools we'll use for calculations, data analysis, and creating plots. Think of this as getting your calculator, spreadsheet, and graphing tools ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbec34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime\n",
    "import io, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ac1f8",
   "metadata": {},
   "source": [
    "## Step 3: Well Test Analysis Engine\n",
    "\n",
    "This section contains the mathematical engine that analyzes well test data. The engine can:\n",
    "\n",
    "- Calculate flow rates using different reservoir models (Linear PI, Vogel's equations)\n",
    "- Automatically choose the right model based on pressure conditions\n",
    "- Find the best-fit parameters for your well data\n",
    "- Evaluate how reliable the results are using multiple accuracy measures\n",
    "\n",
    "**Key Concept**: We use multiple models because wells behave differently depending on whether they produce single-phase or two-phase flow, and whether the reservoir pressure is above or below the bubble point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560def06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellTestOptimizer:\n",
    "    \"\"\"\n",
    "    Well Test Data Optimizer for PI and SBHP (Notebook-friendly)\n",
    "    \n",
    "    Enhanced with multi-criteria fit quality assessment (v1.2):\n",
    "    - RMSE and relative error % for practical engineering decisions\n",
    "    - R² as supplementary metric (can mislead with low-variance data)\n",
    "    - Improved correlation checks for small groups\n",
    "    - Robust optimization with multiple methods\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.results = []\n",
    "\n",
    "    def calculate_ipr(self, fbhp, sbhp, pbub, pi):\n",
    "        # enforce non-negative inputs\n",
    "        fbhp = max(0.0, float(fbhp))\n",
    "        sbhp = max(0.0, float(sbhp))\n",
    "        pbub = max(0.0, float(pbub))\n",
    "        pi = max(0.0, float(pi))\n",
    "\n",
    "        # Physical: if FBHP > SBHP, no production\n",
    "        if fbhp > sbhp:\n",
    "            return 0.0\n",
    "\n",
    "        # Case 1: Linear PI (single-phase) - FBHP >= Pbub and SBHP > Pbub\n",
    "        if (fbhp >= pbub) and (sbhp > pbub):\n",
    "            ql = pi * (sbhp - fbhp)\n",
    "        # Case 2: Modified Vogel (unsaturated reservoir) - FBHP < Pbub and SBHP > Pbub\n",
    "        elif (fbhp < pbub) and (sbhp > pbub):\n",
    "            ql_at_pbub = pi * (sbhp - pbub)\n",
    "            if pbub > 0.0:\n",
    "                fbhp_pbub_ratio = fbhp / pbub\n",
    "                vogel_component = (pi * pbub / 1.8) * (1 - 0.2 * fbhp_pbub_ratio - 0.8 * fbhp_pbub_ratio**2)\n",
    "                ql = ql_at_pbub + vogel_component\n",
    "            else:\n",
    "                ql = ql_at_pbub\n",
    "        # Case 3: Standard Vogel (saturated reservoir) - SBHP <= Pbub\n",
    "        else:\n",
    "            if sbhp > 0.0:\n",
    "                fbhp_sbhp_ratio = fbhp / sbhp\n",
    "                ql = (pi * sbhp / 1.8) * (1 - 0.2 * fbhp_sbhp_ratio - 0.8 * fbhp_sbhp_ratio**2)\n",
    "            else:\n",
    "                ql = 0.0\n",
    "\n",
    "        return max(0.0, ql)\n",
    "\n",
    "    def calculate_ql_max(self, sbhp, pbub, pi):\n",
    "        return self.calculate_ipr(0.0, sbhp, pbub, pi)\n",
    "\n",
    "    def objective_function(self, params, fbhp_data, q_actual, pbub):\n",
    "        sbhp, pi = params\n",
    "        # penalty for non-physical parameters\n",
    "        if sbhp <= 0 or pi <= 0:\n",
    "            return 1e12\n",
    "        max_fbhp = np.max(fbhp_data)\n",
    "        if sbhp <= max_fbhp:\n",
    "            return 1e12\n",
    "\n",
    "        q_calculated = np.array([self.calculate_ipr(f, sbhp, pbub, pi) for f in fbhp_data])\n",
    "        if np.any(q_calculated < 0):\n",
    "            return 1e12\n",
    "\n",
    "        sse = np.sum((q_actual - q_calculated)**2)\n",
    "        # soft penalty for extreme values\n",
    "        if sbhp > 15000 or pi > 1000:\n",
    "            sse += 1e8\n",
    "        return sse\n",
    "\n",
    "    def optimize_group(self, group_data, pbub, sbhp_guess, pi_guess):\n",
    "        fbhp_data = group_data['Pwf'].values\n",
    "        q_actual = group_data['Total Rate'].values\n",
    "\n",
    "        # data checks\n",
    "        if np.any(fbhp_data <= 0) or np.any(q_actual <= 0):\n",
    "            return {'success': False, 'message': 'Non-positive data values detected'}\n",
    "\n",
    "        # Enhanced correlation check - skip for small groups (≤3 points)\n",
    "        try:\n",
    "            fbhp_variance = np.var(fbhp_data)\n",
    "            rate_variance = np.var(q_actual)\n",
    "            \n",
    "            if fbhp_variance < 1e-10 or rate_variance < 1e-10:\n",
    "                fbhp_rate_correlation = 0.0\n",
    "            else:\n",
    "                correlation_matrix = np.corrcoef(fbhp_data, q_actual)\n",
    "                fbhp_rate_correlation = correlation_matrix[0, 1]\n",
    "                if np.isnan(fbhp_rate_correlation):\n",
    "                    fbhp_rate_correlation = 0.0\n",
    "            \n",
    "            # For small groups (≤3 points), skip correlation check as it's unreliable\n",
    "            if len(group_data) > 3 and fbhp_rate_correlation > 0.9:\n",
    "                return {'success': False, 'message': f'Data quality issue: very strong positive FBHP-rate correlation ({fbhp_rate_correlation:.3f}).'}\n",
    "        except Exception:\n",
    "            fbhp_rate_correlation = 0.0\n",
    "\n",
    "        # More flexible bounds for better convergence\n",
    "        max_fbhp = np.max(fbhp_data)\n",
    "        sbhp_lower = max_fbhp + 50    # Reduced minimum drawdown\n",
    "        sbhp_upper = min(10000.0, max_fbhp + 5000.0)  # Increased upper limit\n",
    "\n",
    "        rate_range = np.max(q_actual) - np.min(q_actual)\n",
    "        fbhp_range = np.max(fbhp_data) - np.min(fbhp_data)\n",
    "        estimated_pi = (rate_range / fbhp_range) if fbhp_range > 1 else 1.0  # Relaxed threshold\n",
    "        pi_lower = max(0.001, estimated_pi * 0.01)   # Much wider range\n",
    "        pi_upper = min(100.0, estimated_pi * 100)    # Much wider range\n",
    "\n",
    "        # Adjust initial guesses to bounds\n",
    "        sbhp_guess = float(np.clip(sbhp_guess, sbhp_lower + 100, sbhp_upper - 100)) if sbhp_upper - sbhp_lower > 200 else (sbhp_lower + 200.0)\n",
    "        pi_guess = float(np.clip(pi_guess, pi_lower, pi_upper))\n",
    "\n",
    "        initial_guess = [sbhp_guess, pi_guess]\n",
    "        bounds = [(sbhp_lower, sbhp_upper), (pi_lower, pi_upper)]\n",
    "\n",
    "        # Try multiple optimization methods for robustness\n",
    "        result = None\n",
    "        methods = ['L-BFGS-B', 'TNC', 'SLSQP']\n",
    "        \n",
    "        for method in methods:\n",
    "            try:\n",
    "                result = minimize(self.objective_function, initial_guess, \n",
    "                                args=(fbhp_data, q_actual, pbub), method=method, bounds=bounds)\n",
    "                if result.success:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # If all methods failed, try with relaxed bounds\n",
    "        if result is None or not result.success:\n",
    "            try:\n",
    "                relaxed_bounds = [(sbhp_lower - 50, sbhp_upper + 1000), \n",
    "                                (pi_lower * 0.1, pi_upper * 2)]\n",
    "                result = minimize(self.objective_function, initial_guess,\n",
    "                                args=(fbhp_data, q_actual, pbub), method='L-BFGS-B', bounds=relaxed_bounds)\n",
    "            except Exception:\n",
    "                return {'success': False, 'message': 'All optimization methods failed'}\n",
    "\n",
    "        if result and result.success:\n",
    "            sbhp_opt, pi_opt = result.x\n",
    "            q_calculated = np.array([self.calculate_ipr(f, sbhp_opt, pbub, pi_opt) for f in fbhp_data])\n",
    "            \n",
    "            # Enhanced metrics calculation\n",
    "            ss_res = np.sum((q_actual - q_calculated)**2)\n",
    "            ss_tot = np.sum((q_actual - np.mean(q_actual))**2)\n",
    "            \n",
    "            # Calculate comprehensive metrics\n",
    "            if ss_tot == 0:\n",
    "                r_squared = 0.0\n",
    "                rmse = np.sqrt(np.mean((q_actual - q_calculated)**2))\n",
    "                fit_quality = \"identical_data\"\n",
    "            else:\n",
    "                r_squared = 1 - (ss_res / ss_tot)\n",
    "                rmse = np.sqrt(ss_res / len(q_actual))\n",
    "            \n",
    "            # Additional metrics\n",
    "            mean_abs_error = np.mean(np.abs(q_actual - q_calculated))\n",
    "            mean_actual = np.mean(q_actual)\n",
    "            mean_rel_error = (mean_abs_error / mean_actual) * 100 if mean_actual > 0 else 0\n",
    "            \n",
    "            # Enhanced fit quality assessment using multiple criteria\n",
    "            rmse_percent = (rmse / mean_actual) * 100 if mean_actual > 0 else 100\n",
    "            \n",
    "            # Multi-criteria fit quality assessment\n",
    "            if rmse_percent <= 5.0 and mean_rel_error <= 3.0:\n",
    "                fit_quality = \"excellent\"\n",
    "            elif rmse_percent <= 10.0 and mean_rel_error <= 7.0:\n",
    "                fit_quality = \"good\"\n",
    "            elif rmse_percent <= 20.0 and mean_rel_error <= 15.0:\n",
    "                fit_quality = \"fair\"\n",
    "            elif rmse_percent <= 40.0 or r_squared >= 0.3:\n",
    "                fit_quality = \"poor\"\n",
    "            else:\n",
    "                fit_quality = \"very_poor\"\n",
    "            \n",
    "            # Override for special cases\n",
    "            if ss_tot == 0:\n",
    "                fit_quality = \"identical_data\"\n",
    "            elif r_squared >= 0.9 and rmse_percent <= 15.0:\n",
    "                fit_quality = \"excellent\"\n",
    "            elif r_squared <= -2.0 and rmse_percent > 30.0:\n",
    "                fit_quality = \"very_poor\"\n",
    "            \n",
    "            return {\n",
    "                'sbhp': float(sbhp_opt), 'pi': float(pi_opt), 'r_squared': float(r_squared), \n",
    "                'rmse': float(rmse), 'mean_abs_error': float(mean_abs_error), \n",
    "                'mean_rel_error': float(mean_rel_error), 'fit_quality': fit_quality, \n",
    "                'sse': float(result.fun), 'success': True,\n",
    "                'q_actual': q_actual.tolist(), 'q_calculated': q_calculated.tolist(), \n",
    "                'fbhp': fbhp_data.tolist(), 'dates': group_data['Test Date'].values,\n",
    "            }\n",
    "        else:\n",
    "            return {'success': False, 'message': 'Optimization failed to converge'}\n",
    "\n",
    "    def process_data(self, data, pbub, sbhp_guess, pi_guess, group_size=5):\n",
    "        data_sorted = data.sort_values('Test Date').reset_index(drop=True)\n",
    "        self.data = data_sorted\n",
    "        self.results = []\n",
    "        num_groups = len(data_sorted) // group_size\n",
    "        for i in range(num_groups):\n",
    "            start_idx = i * group_size\n",
    "            end_idx = start_idx + group_size\n",
    "            group_data = data_sorted.iloc[start_idx:end_idx]\n",
    "            res = self.optimize_group(group_data, pbub, sbhp_guess, pi_guess)\n",
    "            if res.get('success'):\n",
    "                res['group_id'] = i+1\n",
    "                res['start_date'] = group_data['Test Date'].min()\n",
    "                res['end_date'] = group_data['Test Date'].max()\n",
    "                self.results.append(res)\n",
    "        return self.results\n",
    "\n",
    "    def generate_ipr_curve(self, sbhp, pbub, pi):\n",
    "        fbhp_range = np.linspace(0.0, float(sbhp), 100)\n",
    "        q_range = np.array([self.calculate_ipr(f, sbhp, pbub, pi) for f in fbhp_range])\n",
    "        return fbhp_range, q_range\n",
    "\n",
    "# End of enhanced class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e640661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Exercise: Compare fit quality assessment methods\n",
    "if 'df' in globals():\n",
    "    print(\"Enhanced Fit Quality Assessment Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Run optimization with different group sizes\n",
    "    for group_size_test in [3, 5, 10]:\n",
    "        optimizer = WellTestOptimizer()\n",
    "        res = optimizer.process_data(df, pbub=4000.0, sbhp_guess=3500.0, pi_guess=1.0, group_size=group_size_test)\n",
    "        \n",
    "        if res:\n",
    "            print(f\"\\nGroup Size {group_size_test}: {len(res)} results\")\n",
    "            for r in res[:3]:  # Show first 3 results\n",
    "                print(f\"  Group {r['group_id']}: R²={r['r_squared']:.3f}, \"\n",
    "                      f\"RMSE={r['rmse']:.1f}, Error%={r['mean_rel_error']:.1f}%, \"\n",
    "                      f\"Quality={r['fit_quality']}\")\n",
    "            \n",
    "            # Count quality categories\n",
    "            quality_counts = {}\n",
    "            for r in res:\n",
    "                quality = r['fit_quality']\n",
    "                quality_counts[quality] = quality_counts.get(quality, 0) + 1\n",
    "            print(f\"  Quality distribution: {quality_counts}\")\n",
    "        else:\n",
    "            print(f\"\\nGroup Size {group_size_test}: No successful results\")\n",
    "    \n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(\"• R² can be misleading for engineering applications\")\n",
    "    print(\"• Error% and RMSE provide practical accuracy measures\")\n",
    "    print(\"• Multi-criteria assessment gives better engineering decisions\")\n",
    "else:\n",
    "    print('Upload the CSV (Test-1 welltestdata.csv) and run the data load cell first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0a041",
   "metadata": {},
   "source": [
    "## Understanding R² vs RMSE for Engineering Applications\n",
    "\n",
    "**Critical Engineering Insight**: R² alone can be highly misleading for well test analysis!\n",
    "\n",
    "### Why R² Can Mislead Engineers\n",
    "\n",
    "The coefficient of determination (R²) measures how well a model explains data variance:\n",
    "- **R² = 1 - (Model Error / Data Variance)**\n",
    "- For **low-variance datasets** (stable flow rates), even accurate models get poor R²\n",
    "- **Engineering reality**: A model predicting 1000±10 bbl/day with 5 bbl/day accuracy is excellent!\n",
    "- **Statistical reality**: R² could be negative if the model doesn't follow minor fluctuations\n",
    "\n",
    "### Example Scenario\n",
    "```\n",
    "Actual rates: [995, 1000, 1005, 998, 1002] bbl/day (very stable production)\n",
    "Model predicts: [1000, 1000, 1000, 1000, 1000] bbl/day (constant rate)\n",
    "\n",
    "RMSE: 3.5 bbl/day (excellent engineering accuracy!)\n",
    "R²: Could be negative (poor statistical fit)\n",
    "Engineering Decision: Model is field-ready and highly accurate\n",
    "```\n",
    "\n",
    "### Multi-Criteria Assessment Used in This Tool\n",
    "\n",
    "**Primary Metrics for Engineering Decisions:**\n",
    "1. **RMSE** (Root Mean Square Error): Absolute accuracy in bbl/day units\n",
    "2. **Relative Error %**: Practical accuracy as percentage of mean flow rate\n",
    "3. **R²**: Supplementary statistical correlation measure\n",
    "\n",
    "**Practical Fit Quality Criteria:**\n",
    "- **Excellent**: ≤5% relative error (field-ready accuracy)\n",
    "- **Good**: ≤10% relative error (suitable for most engineering applications)  \n",
    "- **Fair**: ≤20% relative error (acceptable for screening studies)\n",
    "- **Poor**: >20% relative error but some correlation exists\n",
    "- **Very Poor**: >40% relative error with poor correlation\n",
    "\n",
    "**Recommendation**: Prioritize RMSE and relative error % for engineering decisions. Use R² as supplementary information for statistical model assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical Demonstration: R² vs RMSE for Engineering Decisions\n",
    "if 'results' in globals() and len(results) > 0:\n",
    "    print(\"Demonstration: Why R² Can Mislead Engineers\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find examples of different R² vs practical accuracy patterns\n",
    "    for i, res in enumerate(results):\n",
    "        r2 = res['r_squared']\n",
    "        rmse = res['rmse']\n",
    "        error_pct = res['mean_rel_error']\n",
    "        quality = res['fit_quality']\n",
    "        \n",
    "        # Look for interesting cases\n",
    "        if r2 < 0.5 and error_pct < 10:  # Poor R² but good practical accuracy\n",
    "            print(f\"\\n📊 Group {res['group_id']} - R² MISLEADING CASE:\")\n",
    "            print(f\"   R² = {r2:.3f} (poor statistical fit)\")\n",
    "            print(f\"   RMSE = {rmse:.1f} bbl/day (good engineering accuracy)\")\n",
    "            print(f\"   Error% = {error_pct:.1f}% (excellent field accuracy)\")\n",
    "            print(f\"   Quality = {quality} (multi-criteria assessment)\")\n",
    "            print(f\"   👍 Engineering Decision: This model is field-ready!\")\n",
    "            print(f\"   ❌ R²-only Decision: Would reject this excellent model\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"No clear R² vs practical accuracy disconnect found in current results.\")\n",
    "        print(\"Try different group sizes or datasets to see this phenomenon.\")\n",
    "    \n",
    "    # Show the old vs new assessment comparison\n",
    "    print(f\"\\nComparison of Assessment Methods:\")\n",
    "    print(f\"{'Group':<6}{'R²':<8}{'RMSE':<8}{'Error%':<8}{'Old(R²)':<12}{'New(Multi)':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for res in results[:5]:  # Show first 5 results\n",
    "        r2 = res['r_squared']\n",
    "        rmse = res['rmse']\n",
    "        error_pct = res['mean_rel_error']\n",
    "        new_quality = res['fit_quality']\n",
    "        \n",
    "        # Simulate old R²-only assessment\n",
    "        if r2 >= 0.8:\n",
    "            old_quality = \"excellent\"\n",
    "        elif r2 >= 0.5:\n",
    "            old_quality = \"good\" \n",
    "        elif r2 >= 0.0:\n",
    "            old_quality = \"poor\"\n",
    "        else:\n",
    "            old_quality = \"very_poor\"\n",
    "            \n",
    "        print(f\"{res['group_id']:<6}{r2:<8.3f}{rmse:<8.1f}{error_pct:<8.1f}{old_quality:<12}{new_quality:<12}\")\n",
    "    \n",
    "    print(f\"\\nKey Insight: Multi-criteria assessment better identifies field-ready models!\")\n",
    "else:\n",
    "    print(\"Run the optimization first to see the R² vs RMSE demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66084995",
   "metadata": {},
   "source": [
    "## Learning Exercises\n",
    "\n",
    "Try these exercises to understand how well test analysis works in practice. Work through them at your own pace.\n",
    "\n",
    "### Basic Analysis Exercises\n",
    "\n",
    "**Exercise 1 - Group Size Effects**: \n",
    "Change the `group_size` parameter (try 1, 3, 5, 10) and observe how the productivity index (PI) and reservoir pressure (SBHP) results change. \n",
    "- *Question*: Why do smaller groups give more variable results?\n",
    "- *Question*: Why do larger groups give more stable but possibly less accurate results?\n",
    "\n",
    "**Exercise 2 - Bubble Point Impact**: \n",
    "Change the `pbub` (bubble point pressure) value (try 3000, 4000, 5000 psi) and see how it affects the flow rate calculations and curve shapes.\n",
    "- *Question*: How does bubble point pressure affect the IPR curve shape?\n",
    "- *Question*: Which pressure ranges use which flow models?\n",
    "\n",
    "**Exercise 3 - Data Quality**: \n",
    "Try modifying one data point (make one pressure value unrealistic) and run the analysis again.\n",
    "- *Question*: How does the system detect bad data?\n",
    "- *Question*: What warnings do you get, and why are they important?\n",
    "\n",
    "### Advanced Understanding Exercises\n",
    "\n",
    "**Exercise 4 - Model Evaluation**: \n",
    "Look for wells where R² (statistical fit) is poor but RMSE (engineering accuracy) is good.\n",
    "- *Question*: When would you trust a model with poor R² but good RMSE?\n",
    "- *Question*: Which metric matters more for field operations?\n",
    "\n",
    "**Exercise 5 - Engineering Decisions**: \n",
    "Compare the \"old\" R²-only method with the new multi-criteria assessment.\n",
    "- *Question*: Find cases where the two methods disagree - which would you trust?\n",
    "- *Question*: What does \"field-ready\" accuracy mean for a production engineer?\n",
    "\n",
    "### What to Include in Your Analysis\n",
    "\n",
    "For each exercise, document:\n",
    "- **Your hypothesis**: What do you expect to see?\n",
    "- **Your procedure**: What you changed and why\n",
    "- **Your observations**: Numbers, plots, and patterns you notice\n",
    "- **Engineering interpretation**: What this means for real well operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed674b2d",
   "metadata": {},
   "source": [
    "## What Data You Need\n",
    "\n",
    "Your well test data should be in a CSV file with these columns:\n",
    "\n",
    "- **Test Date**: When each test was conducted (any standard date format)\n",
    "- **Pwf**: Flowing Bottom Hole Pressure (psi) - the pressure in the wellbore while producing\n",
    "- **Total Rate**: Liquid production rate (barrels per day) - how much oil/liquid the well produces\n",
    "\n",
    "**Important**: All pressure and rate values must be positive numbers. The analysis works best when data is arranged chronologically (oldest to newest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602cd027",
   "metadata": {},
   "source": [
    "## Quick Start Guide\n",
    "\n",
    "**How to use this notebook:**\n",
    "\n",
    "1. **Upload your data**: Use the Files panel on the left to upload your `Test-1 welltestdata.csv` file\n",
    "2. **Run the setup**: Execute the Import Tools section above (click the play button on each cell)\n",
    "3. **Load your data**: Run the data loading section below to read your CSV file\n",
    "4. **Run the analysis**: Execute the optimization section to analyze your well data\n",
    "5. **View results**: Look at the plots and tables to understand your well's performance\n",
    "\n",
    "**Tips for getting good results:**\n",
    "- Try different `group_size` values (3, 5, or 10) to see which gives the most stable results\n",
    "- Adjust `pbub` (bubble point pressure) based on your reservoir fluid properties\n",
    "- Check the fit quality metrics to see how reliable your results are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427289",
   "metadata": {},
   "source": [
    "## System Requirements\n",
    "\n",
    "**What you need:**\n",
    "- Google Colab (free) - works in any web browser\n",
    "- Your well test data in CSV format\n",
    "- About 30-60 minutes for the full analysis\n",
    "\n",
    "**Note**: Google Colab already has all the mathematical tools we need installed. If you're running this on your own computer, you might need to install: pandas, numpy, matplotlib, scipy, and openpyxl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae363c17",
   "metadata": {},
   "source": [
    "## Step 4: Load Your Well Test Data\n",
    "\n",
    "Upload your well test data file (`Test-1 welltestdata.csv`) using the Files panel on the left side of Colab. \n",
    "\n",
    "**To upload a file:**\n",
    "1. Click the folder icon in the left panel\n",
    "2. Click \"Upload\" and select your CSV file\n",
    "3. Wait for the upload to complete\n",
    "4. Run the data loading cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab helper: mount Google Drive and copy the example CSV into the session\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import shutil\n",
    "    drive.mount('/content/drive')\n",
    "    drive_src = '/content/drive/My Drive/ColabNotebooks/Test-1 welltestdata.csv'\n",
    "    if os.path.exists(drive_src):\n",
    "        shutil.copy(drive_src, './')\n",
    "        print('Copied Test-1 welltestdata.csv from Drive to session directory.')\n",
    "    else:\n",
    "        print('File not found at', drive_src, '\\nPlace the CSV in Drive under \"My Drive/ColabNotebooks/\" or upload via Files pane.')\n",
    "except Exception as e:\n",
    "    print('Drive mount not available in this environment or error occurred:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to load the provided example file\n",
    "csv_path = 'Test-1 welltestdata.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path, parse_dates=['Test Date'])\n",
    "    df = df.sort_values('Test Date').reset_index(drop=True)\n",
    "    print(f'Loaded {len(df)} records from {csv_path}')\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f'File not found: {csv_path} -- upload it to the Colab session or drive and update the path.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2bffca",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Your Well Data\n",
    "\n",
    "Now we'll analyze your well test data to find the best productivity index (PI) and reservoir pressure (SBHP) values. \n",
    "\n",
    "**Parameters you can adjust:**\n",
    "- `pbub`: Bubble point pressure of your reservoir fluid (psi)\n",
    "- `sbhp_guess`: Your initial estimate of reservoir pressure (psi)  \n",
    "- `pi_guess`: Your initial estimate of productivity index (bbl/day/psi)\n",
    "- `group_size`: How many data points to analyze together\n",
    "\n",
    "The analysis will automatically find the best parameters and tell you how reliable the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (tweak as needed)\n",
    "pbub = 4000.0\n",
    "sbhp_guess = 3500.0\n",
    "pi_guess = 1.0\n",
    "group_size = 5\n",
    "\n",
    "# Run optimizer if df exists\n",
    "if 'df' in globals():\n",
    "    optimizer = WellTestOptimizer()\n",
    "    results = optimizer.process_data(df, pbub, sbhp_guess, pi_guess, group_size)\n",
    "    print(f'Optimization complete. Found results for {len(results)} groups.')\n",
    "    \n",
    "    # Convert results to DataFrame for display\n",
    "    if len(results) > 0:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df['start_date'] = pd.to_datetime(results_df['start_date']).dt.strftime('%Y-%m-%d')\n",
    "        results_df['end_date'] = pd.to_datetime(results_df['end_date']).dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Display enhanced results with new metrics\n",
    "        display_cols = ['group_id', 'start_date', 'end_date', 'sbhp', 'pi', \n",
    "                       'r_squared', 'rmse', 'mean_rel_error', 'fit_quality']\n",
    "        display_df = results_df[display_cols].copy()\n",
    "        display_df.columns = ['Group', 'Start Date', 'End Date', 'SBHP (psi)', \n",
    "                             'PI (bbl/day/psi)', 'R²', 'RMSE', 'Error %', 'Fit Quality']\n",
    "        \n",
    "        # Round numerical columns for better display\n",
    "        display_df['SBHP (psi)'] = display_df['SBHP (psi)'].round(0)\n",
    "        display_df['PI (bbl/day/psi)'] = display_df['PI (bbl/day/psi)'].round(3)\n",
    "        display_df['R²'] = display_df['R²'].round(3)\n",
    "        display_df['RMSE'] = display_df['RMSE'].round(1)\n",
    "        display_df['Error %'] = display_df['Error %'].round(1)\n",
    "        \n",
    "        print(\"\\nOptimization Results with Enhanced Fit Quality Assessment:\")\n",
    "        print(\"=\" * 80)\n",
    "        display(display_df)\n",
    "        \n",
    "        print(\"\\nFit Quality Assessment Notes:\")\n",
    "        print(\"• RMSE: Root Mean Square Error in flow rate units (bbl/day)\")\n",
    "        print(\"• Error %: Mean relative error as percentage of actual flow rates\")\n",
    "        print(\"• R²: Coefficient of determination (can be negative for poor fits)\")\n",
    "        print(\"• Fit Quality: Multi-criteria assessment prioritizing practical accuracy\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        excellent_count = sum(1 for r in results if r['fit_quality'] == 'excellent')\n",
    "        good_count = sum(1 for r in results if r['fit_quality'] == 'good')\n",
    "        total_count = len(results)\n",
    "        success_rate = ((excellent_count + good_count) / total_count) * 100 if total_count > 0 else 0\n",
    "        \n",
    "        print(f\"\\nSummary: {excellent_count} excellent + {good_count} good = {success_rate:.1f}% success rate\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No successful optimizations found. Check data quality and parameters.\")\n",
    "else:\n",
    "    print('No data loaded; please upload the CSV and run this cell again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87f46f",
   "metadata": {},
   "source": [
    "## Step 6: View Your Results\n",
    "\n",
    "These plots help you understand your well's performance and how reliable the analysis is.\n",
    "\n",
    "**Plot 1 - Parameter Trends**: Shows how productivity index and reservoir pressure change over time, with colors indicating result quality.\n",
    "\n",
    "**Plot 2 - Model Accuracy**: Compares actual flow rates to calculated values. Points close to the red line mean the model is accurate.\n",
    "\n",
    "**Plot 3 - IPR Curves**: Shows the theoretical relationship between pressure and flow rate for your well, with your actual test data overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results' in globals() and len(results) > 0:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Enhanced Plot 1: Parameter trends with fit quality\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    \n",
    "    # SBHP trend\n",
    "    colors = ['green' if fq in ['excellent', 'good'] else 'orange' if fq == 'fair' else 'red' \n",
    "             for fq in results_df['fit_quality']]\n",
    "    ax1.scatter(results_df['group_id'], results_df['sbhp'], c=colors, s=80, alpha=0.7, edgecolor='black')\n",
    "    ax1.plot(results_df['group_id'], results_df['sbhp'], 'b-', alpha=0.5, linewidth=1)\n",
    "    ax1.set_ylabel('SBHP (psi)', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_title('Optimized Parameters by Group (Color = Fit Quality)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # PI trend\n",
    "    ax2.scatter(results_df['group_id'], results_df['pi'], c=colors, s=80, alpha=0.7, edgecolor='black')\n",
    "    ax2.plot(results_df['group_id'], results_df['pi'], 'r-', alpha=0.5, linewidth=1)\n",
    "    ax2.set_ylabel('PI (bbl/day/psi)', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Error percentage trend\n",
    "    ax3.scatter(results_df['group_id'], results_df['mean_rel_error'], c=colors, s=80, alpha=0.7, edgecolor='black')\n",
    "    ax3.plot(results_df['group_id'], results_df['mean_rel_error'], 'purple', alpha=0.5, linewidth=1)\n",
    "    ax3.set_ylabel('Error %', fontsize=12)\n",
    "    ax3.set_xlabel('Group ID', fontsize=12)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.axhline(y=10, color='orange', linestyle='--', alpha=0.7, label='10% threshold')\n",
    "    ax3.axhline(y=5, color='green', linestyle='--', alpha=0.7, label='5% threshold')\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Enhanced Plot 2: Actual vs Calculated with metrics for best group\n",
    "    best_group_idx = np.argmin([r['mean_rel_error'] for r in results])\n",
    "    selected = results[best_group_idx]\n",
    "    \n",
    "    q_act = np.array(selected['q_actual'])\n",
    "    q_calc = np.array(selected['q_calculated'])\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(q_act, q_calc, alpha=0.8, s=80, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Perfect fit line\n",
    "    mn = min(q_act.min(), q_calc.min()) * 0.95\n",
    "    mx = max(q_act.max(), q_calc.max()) * 1.05\n",
    "    plt.plot([mn,mx], [mn,mx], 'r--', linewidth=2, label='Perfect Fit')\n",
    "    \n",
    "    # ±10% error bands\n",
    "    plt.fill_between([mn,mx], [mn*0.9, mx*0.9], [mn*1.1, mx*1.1], \n",
    "                    alpha=0.1, color='green', label='±10% Error Band')\n",
    "    \n",
    "    plt.xlabel('Actual Rate (bbl/day)', fontsize=12)\n",
    "    plt.ylabel('Calculated Rate (bbl/day)', fontsize=12)\n",
    "    plt.title(f'Actual vs Calculated (Group {selected[\"group_id\"]} - Best Fit)\\n'\n",
    "             f'R² = {selected[\"r_squared\"]:.3f}, RMSE = {selected[\"rmse\"]:.1f}, '\n",
    "             f'Error% = {selected[\"mean_rel_error\"]:.1f}%', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    # Add text box with metrics explanation\n",
    "    textstr = f'Fit Quality: {selected[\"fit_quality\"].title()}\\nThis model explains the data with {selected[\"mean_rel_error\"]:.1f}% average error'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "    plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Enhanced Plot 3: IPR curves overlay with improved legend\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(results)))\n",
    "    \n",
    "    for i, res in enumerate(results):\n",
    "        fb, ql = optimizer.generate_ipr_curve(res['sbhp'], pbub, res['pi'])\n",
    "        \n",
    "        # Line style based on fit quality\n",
    "        if res['fit_quality'] in ['excellent', 'good']:\n",
    "            linestyle = '-'\n",
    "            alpha = 0.8\n",
    "        else:\n",
    "            linestyle = '--'\n",
    "            alpha = 0.5\n",
    "            \n",
    "        plt.plot(ql, fb, color=colors[i], linestyle=linestyle, alpha=alpha, linewidth=2,\n",
    "                label=f\"Group {res['group_id']} ({res['fit_quality']}, {res['mean_rel_error']:.1f}% err)\")\n",
    "        \n",
    "        # Plot measured data points\n",
    "        plt.scatter(res['q_actual'], res['fbhp'], color=colors[i], \n",
    "                   edgecolor='black', alpha=0.8, s=60, linewidth=1)\n",
    "    \n",
    "    plt.xlabel('Liquid Flow Rate (bbl/day)', fontsize=12)\n",
    "    plt.ylabel('FBHP (psi)', fontsize=12)\n",
    "    plt.title('IPR Curves with Measured Data\\n(Solid lines = good fits, Dashed = poor fits)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improved legend positioning\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary metrics table\n",
    "    summary_data = []\n",
    "    for res in results:\n",
    "        summary_data.append({\n",
    "            'Group': res['group_id'],\n",
    "            'SBHP': f\"{res['sbhp']:.0f}\",\n",
    "            'PI': f\"{res['pi']:.3f}\",\n",
    "            'R²': f\"{res['r_squared']:.3f}\",\n",
    "            'RMSE': f\"{res['rmse']:.1f}\",\n",
    "            'Error%': f\"{res['mean_rel_error']:.1f}\",\n",
    "            'Quality': res['fit_quality']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\nDetailed Results Summary:\")\n",
    "    print(\"=\" * 70)\n",
    "    display(summary_df)\n",
    "    \n",
    "else:\n",
    "    print('No optimization results to plot. Run the optimization cell first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abebd9",
   "metadata": {},
   "source": [
    "## Step 7: Save Your Results (Optional)\n",
    "\n",
    "You can save your analysis results to an Excel file to use in reports or share with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: save results to Excel locally (or to Colab drive)\n",
    "if 'results_df' in globals():\n",
    "    out_name = 'well_test_results.xlsx'\n",
    "    results_df.to_excel(out_name, index=False)\n",
    "    print(f'Saved results to {out_name}')\n",
    "else:\n",
    "    print('No results to save.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc518d57",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: What You've Learned\n",
    "\n",
    "**Analysis Capabilities:**\n",
    "- **Multi-criteria evaluation**: The system uses multiple measures (RMSE, relative error %, and R²) to assess how good your results are\n",
    "- **Automatic quality checking**: Built-in validation helps identify data problems and unreliable results\n",
    "- **Robust calculations**: The analysis handles challenging data and provides reliable engineering parameters\n",
    "- **Visual understanding**: Multiple plots help you see patterns and evaluate result quality\n",
    "\n",
    "**Key Engineering Insights:**\n",
    "- **R² limitations**: Statistical measures like R² can sometimes mislead engineers, especially with stable production data\n",
    "- **Practical accuracy**: RMSE and relative error % often give better measures of real-world model usefulness\n",
    "- **Engineering judgment**: Understanding when to trust models despite imperfect statistical fits is crucial for field applications\n",
    "- **Quality assessment**: Multiple criteria help identify field-ready models that single-metric approaches might reject\n",
    "\n",
    "**What This Means for Field Work:**\n",
    "- **Better decisions**: Multi-criteria assessment helps you choose models suitable for field development\n",
    "- **Quality understanding**: You can now evaluate when results are reliable enough for engineering decisions\n",
    "- **Practical focus**: The analysis prioritizes engineering accuracy over statistical perfection\n",
    "- **Real-world application**: Results include guidance on when models are ready for field implementation\n",
    "\n",
    "**Further Learning:**\n",
    "- Try the analysis with different well datasets to see how reservoir characteristics affect results\n",
    "- Experiment with various bubble point pressures to understand flow regime transitions\n",
    "- Practice interpreting the quality metrics to develop engineering judgment for model evaluation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
